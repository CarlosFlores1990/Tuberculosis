{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\ndata_dir = '/kaggle/input/curated-chest-xray-image-dataset-for-covid19/Curated X-Ray Dataset'\n\n# Obtener una lista de las clases (nombres de las carpetas)\nclasses = os.listdir(data_dir)\n\n# Imprimir la cantidad de imágenes en cada clase\nfor class_name in classes:\n    class_dir = os.path.join(data_dir, class_name)\n    num_images = len(os.listdir(class_dir))\n    print(f'Clase: {class_name}, Cantidad de Imágenes: {num_images}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T01:38:07.046125Z","iopub.execute_input":"2023-10-01T01:38:07.047467Z","iopub.status.idle":"2023-10-01T01:38:07.573892Z","shell.execute_reply.started":"2023-10-01T01:38:07.047375Z","shell.execute_reply":"2023-10-01T01:38:07.572411Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Clase: Normal, Cantidad de Imágenes: 3270\nClase: COVID-19, Cantidad de Imágenes: 1281\nClase: Pneumonia-Viral, Cantidad de Imágenes: 1656\nClase: Pneumonia-Bacterial, Cantidad de Imágenes: 3001\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Ruta de la carpeta original con las imágenes\ndata_dir = '/kaggle/input/curated-chest-xray-image-dataset-for-covid19/Curated X-Ray Dataset'\n\n# Directorio donde se guardarán las imágenes aumentadas\naugmented_dir = '/kaggle/working/augmented_data'\n\n# Crea el directorio si no existe\nif not os.path.exists(augmented_dir):\n    os.makedirs(augmented_dir)\n\n# Definir las clases basadas en las carpetas dentro de data_dir\nclasses = ['COVID-19', 'Normal', 'Pneumonia-Bacterial', 'Pneumonia-Viral']\n\n# Obtener la cantidad máxima de imágenes entre todas las clases\nmax_images_per_class = max([len(os.listdir(os.path.join(data_dir, class_name))) for class_name in classes])\n\n# Crear un generador de aumento de datos para todas las clases\ndatagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Crear un directorio temporal para las imágenes aumentadas\ntemp_augmented_dir = os.path.join(augmented_dir, 'temp')\nos.makedirs(temp_augmented_dir, exist_ok=True)\n\n# Generar imágenes aumentadas y guardarlas en el directorio temporal\nfor class_name in classes:\n    class_dir = os.path.join(data_dir, class_name)\n    num_images = len(os.listdir(class_dir))\n\n    # Si la clase tiene menos imágenes que la cantidad máxima, generar imágenes aumentadas\n    if num_images < max_images_per_class:\n        target_dir = os.path.join(temp_augmented_dir, class_name)\n        os.makedirs(target_dir, exist_ok=True)\n        \n        image_files = [os.path.join(class_dir, img_name) for img_name in os.listdir(class_dir)]\n        image_generator = datagen.flow_from_directory(\n            data_dir,\n            target_size=(224, 224),\n            batch_size=32,\n            classes=[class_name],\n            save_to_dir=target_dir,\n            save_prefix='aug',\n            save_format='jpeg'\n        )\n        num_augmented_images = max_images_per_class - num_images  # Cuántas imágenes adicionales necesitamos\n        for _ in range(num_augmented_images // 32):  # Aumentar en lotes de 32 imágenes\n            image_batch, _ = next(image_generator)\n\n# Crear un nuevo directorio equilibrado y copiar todas las imágenes originales y aumentadas\nbalanced_data_dir = '/kaggle/working/balanced_data'\nos.makedirs(balanced_data_dir, exist_ok=True)\n\nfor class_name in classes:\n    source_dir = os.path.join(data_dir, class_name)\n    target_dir = os.path.join(balanced_data_dir, class_name)\n\n    # Crear el directorio de destino si no existe\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Copiar todas las imágenes originales\n    for img_name in os.listdir(source_dir):\n        source_path = os.path.join(source_dir, img_name)\n        target_path = os.path.join(target_dir, img_name)\n        shutil.copy(source_path, target_path)\n\n    # Si es la clase con menos imágenes, copiar también las imágenes aumentadas\n    if class_name in os.listdir(temp_augmented_dir):\n        temp_class_dir = os.path.join(temp_augmented_dir, class_name)\n        for img_name in os.listdir(temp_class_dir):\n            source_path = os.path.join(temp_class_dir, img_name)\n            target_path = os.path.join(target_dir, img_name)\n            shutil.copy(source_path, target_path)\n\n# Imprimir la cantidad de imágenes en cada clase después del aumento y el balanceo\nfor class_name in classes:\n    num_images_after_augmentation = len(os.listdir(os.path.join(balanced_data_dir, class_name)))\n    print(f'Clase: {class_name}, Cantidad de Imágenes después del Aumento y Balanceo: {num_images_after_augmentation}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T01:38:12.433565Z","iopub.execute_input":"2023-10-01T01:38:12.433939Z","iopub.status.idle":"2023-10-01T01:42:19.438696Z","shell.execute_reply.started":"2023-10-01T01:38:12.433913Z","shell.execute_reply":"2023-10-01T01:42:19.436802Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 1281 images belonging to 1 classes.\nFound 3001 images belonging to 1 classes.\nFound 1656 images belonging to 1 classes.\nClase: COVID-19, Cantidad de Imágenes después del Aumento y Balanceo: 3234\nClase: Normal, Cantidad de Imágenes después del Aumento y Balanceo: 3270\nClase: Pneumonia-Bacterial, Cantidad de Imágenes después del Aumento y Balanceo: 3257\nClase: Pneumonia-Viral, Cantidad de Imágenes después del Aumento y Balanceo: 3256\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Ruta del directorio con imágenes balanceadas\nbalanced_data_dir = '/kaggle/working/balanced_data'\n\n# Parámetros\nbatch_size = 32\nepochs = 8\ninput_shape = (224, 224, 3)\n\n# Crear generador de datos para aumento y validación\ndatagen = ImageDataGenerator(\n    rescale=1.0/255,\n    validation_split=0.2\n)\n\n# Cargar datos y dividir en conjuntos de entrenamiento y validación\ntrain_generator = datagen.flow_from_directory(\n    balanced_data_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    balanced_data_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Crear modelo ResNet50\nbase_model = ResNet50(weights='/kaggle/input/tf-keras-pretrained-model-weights/No Top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=input_shape)\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(len(train_generator.class_indices), activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Entrenar el modelo\nhistory = model.fit(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator\n)\n\n# Gráfico de pérdida y precisión\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.tight_layout()\nplt.show()\n\n# Evaluación del modelo en el conjunto de prueba\ntest_generator = datagen.flow_from_directory(\n    balanced_data_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\nprint(f'Test Loss: {test_loss:.4f}')\n\n# Matriz de confusión y reporte de clasificación\nY_pred = model.predict(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = list(train_generator.class_indices.keys())\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))\n\n# Guardar pesos y modelo\nmodel.save('/kaggle/working/resnet50_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T01:52:22.630574Z","iopub.execute_input":"2023-10-01T01:52:22.634276Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 10415 images belonging to 4 classes.\nFound 2602 images belonging to 4 classes.\nEpoch 1/8\n326/326 [==============================] - 5612s 17s/step - loss: 0.7614 - accuracy: 0.7858 - val_loss: 374.4056 - val_accuracy: 0.2483\nEpoch 2/8\n326/326 [==============================] - 4985s 15s/step - loss: 0.4468 - accuracy: 0.8479 - val_loss: 2.3855 - val_accuracy: 0.3128\nEpoch 3/8\n326/326 [==============================] - 5562s 17s/step - loss: 0.2995 - accuracy: 0.8837 - val_loss: 1.0053 - val_accuracy: 0.6030\nEpoch 4/8\n326/326 [==============================] - 4863s 15s/step - loss: 0.1982 - accuracy: 0.9241 - val_loss: 0.3797 - val_accuracy: 0.8413\nEpoch 5/8\n326/326 [==============================] - 5077s 16s/step - loss: 0.1284 - accuracy: 0.9543 - val_loss: 0.3979 - val_accuracy: 0.8716\nEpoch 6/8\n326/326 [==============================] - 5406s 17s/step - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.5199 - val_accuracy: 0.8559\nEpoch 7/8\n326/326 [==============================] - 5490s 17s/step - loss: 0.1879 - accuracy: 0.9405 - val_loss: 0.3645 - val_accuracy: 0.8786\nEpoch 8/8\n306/326 [===========================>..] - ETA: 5:18 - loss: 0.0751 - accuracy: 0.9744","output_type":"stream"}]}]}
